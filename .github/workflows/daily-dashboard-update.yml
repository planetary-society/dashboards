# GitHub Action Workflow: Daily Dashboard Update
#
# This workflow runs daily to:
# 1. Download the latest CSV data for the cancellations dashboard.
# 2. Compare and clean up data files.
# 3. Commit new data if changed.
# 4. Deploy the static D3.js dashboards to GitHub Pages.

name: Daily Dashboard Update

on:
  schedule:
    # runs every day at 10:00 AM Pacific Time (15:00 UTC)
    - cron: '0 17 * * *'
  workflow_dispatch: # Allows manual triggering

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: write   # Required to commit changes
      pages: write      # Required to deploy to GitHub Pages
      id-token: write   # Required for trusted deployment

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Download latest CSV from GitHub
        id: download
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p data

          # Find the latest CSV filename and extract date
          LATEST_FILE=$(gh api repos/planetary-society/nasa-cancellations-tracking/contents/consolidated \
            --jq '[.[] | select(.name | endswith(".csv"))] | sort_by(.name) | last | .name')
          DATE=$(echo "$LATEST_FILE" | grep -oE '[0-9]{4}-[0-9]{2}-[0-9]{2}')

          echo "Latest source file: $LATEST_FILE (date: $DATE)"
          echo "source_date=$DATE" >> $GITHUB_OUTPUT

          # Download directly to data directory
          curl -fL -o "data/nasa_cancelled_contracts_${DATE}.csv" \
            "https://raw.githubusercontent.com/planetary-society/nasa-cancellations-tracking/main/consolidated/${LATEST_FILE}"

      - name: Compare and update if changed
        id: compare
        run: |
          DOCS_FILE="docs/data/cancellations/nasa_cancelled_contracts_latest.csv"
          DATA_FILE="data/nasa_cancelled_contracts_${{ steps.download.outputs.source_date }}.csv"
          mkdir -p docs/data/cancellations

          if [[ -f "$DOCS_FILE" ]] && cmp -s "$DATA_FILE" "$DOCS_FILE"; then
            echo "No changes detected"
            echo "changed=false" >> $GITHUB_OUTPUT
            # Remove the just-downloaded file since it's identical
            rm "$DATA_FILE"
          else
            echo "Changes detected, updating files"
            echo "changed=true" >> $GITHUB_OUTPUT

            # Remove old cancellation CSVs from data dir, keep only the new one
            # Note: Only targets nasa_cancelled_contracts_*.csv - leaves NASA-*.csv files untouched
            find data -name "nasa_cancelled_contracts_*.csv" ! -name "$(basename $DATA_FILE)" -delete

            # Update docs with new file
            cp "$DATA_FILE" "$DOCS_FILE"

            # Update metadata
            echo "{\"lastUpdated\": \"${{ steps.download.outputs.source_date }}\"}" > docs/data/cancellations/metadata.json
            echo "Updated metadata with date: ${{ steps.download.outputs.source_date }}"
          fi

      - name: Commit & push changes
        if: steps.compare.outputs.changed == 'true'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: daily data refresh"
          file_pattern: |
            data/*.csv
            docs/data/**/*

      - name: Configure GitHub Pages
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'docs'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
